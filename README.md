# ğŸ© ğŸª„ A Pinch of PixC Dust ğŸ‡

This python project centralizes librairies to facilitate local studies based on SWOT-HR Level-2 Pixel Cloud products.

# ğŸš€ Quick Start 
start by cloning  this package and installing the environment with  
pip: 
```
pip install -e .
```

poetry:
```
poetry install
```
## ğŸ“” *Notebooks* 
Start here to understand what you can do: "There is nothing more frustrating than a good example" (Mark Twain)

## â¬‡ï¸ *Downloaders* 
The downloader classes allow you to directly download SWOT Pixel Cloud files from hydroweb.next (or other sources such as PO.DAAC to be implemented).  
For hydroweb.next, it requires you to create an account and an API Key (token) from the platform: https://hydroweb.next.theia-land.fr

## ğŸª„ *Converters* 
The converter classes allow you to create more easy-to-use databases than the original netcdf4 format. The various databases are designed for **local** studies, not for huge country-scale databases (though it should work, they will not be efficient).  
Zarr (with zcollection), geopackage and shapefile are currently supported.  
The converters allow you to limit the databases to areas of interest (provided by polygons) and variables of interest (limitated to the pixel_cloud group mono-dimensional variables).  
Users are encouraged to limit the number of variables to what is useful, especially for geopackage format, but also for the planet ;)

## ğŸ‘“ *Readers* :
The reader classes allow you to read the original netcdf4 format or the databases generated by converters.

## ğŸ§° *Tools*
Here are some python script implementing the classes.

## ğŸ”¶ *Discrete Global Grid System (experimental)*
I enjoy DDGS a lot. It is pretty great if you want to perform on-the-fly "rasterization", partitionning, comparing pixels over time or space, etc.  
Currently only H3 is implemented.  
